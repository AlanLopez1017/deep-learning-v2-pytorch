{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlanLopez1017/deep-learning-v2-pytorch/blob/master/PyTorch_preliminares.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yftgPVCOjT0i",
        "outputId": "9b8c08c6-064c-4274-8c55-abbdfc155806"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive._mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "442o87epjka7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('./drive/MyDrive/Python/PyTorch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "woxu8V9gjo6k",
        "outputId": "41ec0c3d-8807-480b-d1c8-832e837fac1b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Python/PyTorch'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RH099lWTjuYr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "149eafab-513a-4005-9d51-6496c35f28ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting d2l\n",
            "  Downloading d2l-0.17.1-py3-none-any.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 613 kB/s \n",
            "\u001b[?25hCollecting numpy==1.18.5\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting pandas==1.2.2\n",
            "  Downloading pandas-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 56.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jupyter==1.0.0 in /usr/local/lib/python3.7/dist-packages (from d2l) (1.0.0)\n",
            "Collecting matplotlib==3.3.3\n",
            "  Downloading matplotlib-3.3.3-cp37-cp37m-manylinux1_x86_64.whl (11.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.6 MB 46.4 MB/s \n",
            "\u001b[?25hCollecting requests==2.25.1\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[K     |████████████████████████████████| 61 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (4.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.6.1)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.2.0)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.3.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (7.6.5)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter==1.0.0->d2l) (5.2.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (3.0.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.3.3->d2l) (1.3.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.2->d2l) (2018.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (2021.10.8)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.25.1->d2l) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib==3.3.3->d2l) (1.15.0)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.3.5)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.5.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter==1.0.0->d2l) (5.1.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter==1.0.0->d2l) (0.2.5)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (3.5.2)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (1.0.2)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (5.1.3)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter==1.0.0->d2l) (0.2.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (2.6.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter==1.0.0->d2l) (4.9.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (1.8.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (2.11.3)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter==1.0.0->d2l) (0.12.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter==1.0.0->d2l) (22.3.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter==1.0.0->d2l) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter==1.0.0->d2l) (2.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.8.4)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (1.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.5.0)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (4.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter==1.0.0->d2l) (0.7.1)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (0.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter==1.0.0->d2l) (21.3)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter==1.0.0->d2l) (2.0.0)\n",
            "Installing collected packages: numpy, requests, pandas, matplotlib, d2l\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.2.2\n",
            "    Uninstalling matplotlib-3.2.2:\n",
            "      Successfully uninstalled matplotlib-3.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas~=1.1.0; python_version >= \"3.0\", but you have pandas 1.2.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.25.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed d2l-0.17.1 matplotlib-3.3.3 numpy-1.18.5 pandas-1.2.2 requests-2.25.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "matplotlib",
                  "mpl_toolkits",
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5Nr9gr9j8nY"
      },
      "source": [
        "# Manipulación de datos\n",
        "Es importante saber como almacenar y manipular datos. Hay dos aspectos relevantes que tenemos que hacer con ellos:\n",
        "* Adquisición\n",
        "* Procesamiento cuando se encuentren en la computadora\n",
        "\n",
        "Para adquirir datos es necesario saber almacenarlos, es por eso que una matriz n-dimensional o también llamado tensor nos será de ayuda.\n",
        "\n",
        "## Inicio\n",
        "Para comenzar se debe importar la librería Torch:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZnYBUQammXUS"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiuiFBMEmlSG"
      },
      "source": [
        "Un tensor representa un arreglo de valores númericos, siendo probablemente multidimensional. De acuerdo a su número de ejes se denomina de las siguientes formas:\n",
        "- 1 eje: vector\n",
        "- 2 ejes: Matrix\n",
        "- k > 2 ejes: $k^{th}$ tensor de orden \n",
        "\n",
        "PyTorch presenta ya funciones para la creación de nuevos tensores con ciertos valores.\n",
        "\n",
        "Ejemplo:\n",
        "Con arange(n) se puede crear un vector de valores uniformes, que empiece en 0 (lo incluye) y termine en n (no lo incluye).\n",
        "\n",
        "Por defecto, el tamaño del intervalo es 1. Los nuevos tensores se almacenan en la memoria principal y se designan para el cálculo basado en la CPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFvcgDrqoyaZ",
        "outputId": "428a7be2-d6f9-4ccb-ee83-8ccc51185090"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(12,dtype = torch.float32)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqYxQeTQo65x"
      },
      "source": [
        "Podemos conocer la forma de un tensor, es decir, la longitud a través de cada eje, mediante la propiedad _shape_.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC273xpypOIA",
        "outputId": "b96ad849-c50d-48fe-c82f-8f5890775155"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([12])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OckXcPfKpQX5"
      },
      "source": [
        "Si lo que queremos es conocer el número total de elementos de un tensor, o visto de otra forma, el producto de los elementos de la forma, cuando se trata de un vector, tiene un sólo elemento en la forma como se pudo observar, y en este caso, es igual a su tamaño (total de elementos del tensor):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBSPFZocp9q5",
        "outputId": "1272d278-3b39-47a8-d81b-f23296af58ff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.numel()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-8t5ExwqBX8"
      },
      "source": [
        "Si deseamos cambiar la forma de un tensor sin modificar el número de elementos ni sus valores, podemos usar la función _reshape_.\n",
        "\n",
        "El vector x con forma (12,) que se ha utilizado se puede transformar en una matriz con forma (3,4). Este nuevo vector tendría los mismos valores pero organizados en 3 filas y 4 columnas. La forma cambió, no obstante, los elementos no:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULqAR5nEqxSx",
        "outputId": "da9d7ef8-7012-4a63-98b7-97b3e67b77b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [ 8.,  9., 10., 11.]])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = x.reshape(3,4)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gypdQOfarKOy"
      },
      "source": [
        "Los tensores pueden calcular de forma automática una dimensión a partir de las demás. En el ejemplo anterior, si la matriz objetivo tenía forma (altura, ancho), y sabiendo cualquiera de esos valores, ya sea, la altura o el ancho, la no conocida se obtiene implícitamente.\n",
        "\n",
        "Para que un tensor realice esto, se remplaza un -1 en la dimensión que queremos que se infiera automáticamente.\n",
        "\n",
        "Para lo que se ha realizado con el vector x, se pudo haber hecho de dos formas:\n",
        "\n",
        "* x.reshape(3,4) lo cambiamos por -> x.reshape(-1,4)\n",
        "* x.reshape(3,4) lo cambiamos por -> x.reshape(3,-1)\n",
        "\n",
        "**Tensores inicializados con cero**\n",
        "\n",
        "Para obtener tensores inicializadas con ceros, se realiza mediante la propiedad _zeros_. El siguiente ejemplo es un tensor con forma (2,3,4):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6u2DEpateBq",
        "outputId": "7af14c1a-16f9-4742-8626-c2dc979766f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.zeros((2,3,4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0lS4pPGtl8y"
      },
      "source": [
        "**Tensores inicializados con unos**\n",
        "\n",
        "Para obtener tensores inicializadas con unos, se realiza mediante la propiedad _ones_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLbrPN9Ktrq5",
        "outputId": "848b0c95-d14d-4755-f395-644c29f43c24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.ones((2,3,4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIDyAjJJt_mR"
      },
      "source": [
        "**Tensores inicializados con valores aleatorios**\n",
        "\n",
        "Un ejemplo de uso de estos tensores es cuando se crean matrices que funcionan como parámetros de una red neuronal, ya que, normalmente sus valores se inicializan con valores aleatorios.\n",
        "\n",
        "El siguiente tensor tiene una forma (5,4) y cada elemento se extrajo aleatoriamente de una distribución gausiana estándar (normal) con una media de 0 y desviación estándar de 1. Para esto, se utiliza la propiedad _randn_.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxfZog6Ivc3c",
        "outputId": "a61d567b-63ad-4206-a8b6-cca39c2ae3bd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.2204, -0.8333,  0.1837,  1.2486],\n",
              "        [-0.5009,  0.1174,  0.7050,  0.7321],\n",
              "        [-1.4421, -1.2758, -1.2015,  0.7555],\n",
              "        [-1.6072,  0.7757, -0.0648,  0.8688],\n",
              "        [-1.4232, -1.9594, -1.8735, -0.6077]])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.randn(5,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A49Mn5FhvfwI"
      },
      "source": [
        "**Tensores con valores específicos**\n",
        "\n",
        "Se pueden especificar valores exactos a cada elemento del tensor dando una lista de Python o bien una lista de listas, que contengan valores numéricos.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3wBOpUnwI8l",
        "outputId": "81e66732-6bbd-4440-d997-b56c8855ae4e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2, 1, 4, 3],\n",
              "        [1, 2, 3, 4],\n",
              "        [4, 3, 2, 1]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ItTuSFXwRA5"
      },
      "source": [
        "## Operaciones \n",
        "Las operaciones elementales aplican una operación escalar estándar a cada elemento de un array.\n",
        "\n",
        "El operador escalar unitario (toma una entrada) se denota como $f : \\mathbb R \\to \\mathbb R$, esto nos dice que la función mapea desde un número real a otro.\n",
        "\n",
        "El operador escalar binario (toma dos entradas reales, y da una entrada) y se denota como $f : \\mathbb R, \\mathbb R \\to \\mathbb R$.\n",
        "\n",
        "Ahora bien, si tenemos dos vectores **u** y **v** de la misma forma, y se tiene un operador binario, podemos producir un vector **c** = F(**u**,**v**), estableciendo $c_i ← f(u_i,v_i)$ para toda $i$, donde $c_i, u_i$ y $v_i$ son los i-ésimos elementos de los vectores.\n",
        "\n",
        "Los operadores aritméticos estándar (suma, resta, multiplicación, división y exponenciación) son operaciones elementales para cualquier tensor de forma idéntica y arbitraria.\n",
        "\n",
        "### Operaciones\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3s257J_59-bO",
        "outputId": "60dcb197-94eb-4668-a41b-610a0894eed3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([ 3.,  4.,  6., 10.])\n",
            "tensor([-1.,  0.,  2.,  6.])\n",
            "tensor([ 2.,  4.,  8., 16.])\n",
            "tensor([0.5000, 1.0000, 2.0000, 4.0000])\n",
            "tensor([ 1.,  4., 16., 64.])\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor([1.0,2,4,8])\n",
        "y = torch.tensor([2,2,2,2])\n",
        "print(x+y) # suma\n",
        "print(x-y) # resta\n",
        "print(x*y) # multiplicación\n",
        "print(x/y) # división\n",
        "print(x**y) # exponenciación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzRMSkN4-_XS"
      },
      "source": [
        "Otra operación es la de exponenciación de la forma $e^x$:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbe2XvYH_HZ8",
        "outputId": "c1d224a2-1129-4770-d821-5d933b8eef08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.exp(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKZz3Y-d_fkB"
      },
      "source": [
        "Además de operaciones elementales, se pueden realizar operaciones de álgebra lineal, como productos punto y multiplicación de matrices.\n",
        "\n",
        "**Concatenar**\n",
        "\n",
        "Los tensores se pueden concatenar, apilándolos de extremo a extremo para formar un tensor más grande. Se debe proporcionar una lista de tensores y establecer a lo largo de qué eje se quiere concatenar.\n",
        "\n",
        "Ejemplo: Concatenar dos matrices de forma (3,4), si se realiza a lo largo de las filas, la matriz resultante tiene una forma de (6,4) que es la suma de las filas de ambas matrices (3+3). Esto se realiza de la siguiente forma:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9oi0PZuC_nU",
        "outputId": "426d475e-d653-437e-8b98-dd11cd124b4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [ 8.,  9., 10., 11.],\n",
              "        [ 2.,  1.,  4.,  3.],\n",
              "        [ 1.,  2.,  3.,  4.],\n",
              "        [ 4.,  3.,  2.,  1.]])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = torch.arange(12, dtype=torch.float32).reshape((3,4))\n",
        "Y = torch.tensor([[2.0, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])\n",
        "torch.cat((X, Y), dim=0) # concatenar a lo largo de las filas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48s7j0ZyDHAy"
      },
      "source": [
        "Se observa que se coloca dim = 0, que representa el primer elemento de la forma que son las filas.\n",
        "\n",
        "Ahora, para hacer la concatenación a lo largo de las columnas, con nuestro ejemplo nos daría una matriz de forma (3,8), que es la suma de las columnas de ambas matrices (4+4), y se coloca el parámetro dim = 1, haciendo referencia al segundo elemento de la forma que son las columnas:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv3dCqIoDfL7",
        "outputId": "ea1f83b1-2f8f-42ee-9ba1-d7fa9e8de991"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
              "        [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
              "        [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cat((X, Y), dim=1) # concatenar a lo largo de las columnas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3CYodYLEA_L"
      },
      "source": [
        "**Tensor binario mediante sentencias lógicas**\n",
        "\n",
        "Si tomamos a X y Y utilizados previamente, y realizamos X == Y para cada posición y resulta que son iguales en ésta, el tensor tendrá un valor de 1, o bien, True, en caso contrario tomara el valor de 0, o bien False."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aFG9Z2yEzSM",
        "outputId": "865828f2-d7a6-4bd7-eb0e-29c9275ab2d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[False,  True, False,  True],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X == Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEV1xZshE-Vq"
      },
      "source": [
        "**Suma de todos los elemento del tensor**\n",
        "\n",
        "La suma de todos los elementos da como resultado un tensor de un solo elemento:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZDSP21OFHJT",
        "outputId": "92df38f4-8bf3-46bc-e82b-f3866b8d5972"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(66.)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8avDjSlFiq9"
      },
      "source": [
        "## Mecanismos de broadcasting\n",
        "Bajo ciertas condiciones, incluso cuando las formas difieren, se pueden realizar operaciones elementales llamando un mecanismo de broadcasting.\n",
        "\n",
        "Primero se amplían una o ambas matrices copiando los elementos de forma correcta, tal que tras esta transformación los dos tensores tengan la misma forma. Posterior, se realizan las operaciones elementales.\n",
        "\n",
        "En la mayoría de los casos se \"difune\" a lo largo de un eje en donde un arreglo tiene inicialmente longitud de 1, esto se muestra:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XQgUoCCGkbM",
        "outputId": "397e0f03-54b0-4613-d680-6564d996c62c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[0],\n",
              "         [1],\n",
              "         [2]]), tensor([[0, 1]]))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.arange(3).reshape(3,1)\n",
        "b = torch.arange(2).reshape(1,2)\n",
        "a,b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaIVqc4THYI0"
      },
      "source": [
        "La forma de a es (3,1) y la forma de b es (1,2), de modo que no coinciden si queremos sumarlas. \n",
        "\n",
        "Para poder sumarlas, se difunden las entradas de ambas matrices en una de forma (3,2). Para a, se replican las columnas, resultado en $a = [[0,0],[1,1],[2,2]]$ y para b, se replican las filas, resultado en $b = [[0,1],[0,1],[0,1]]$. De esta forma, es sencillo obsevar entonces que la suma de a con b, da lo siguiente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9a66A8-Ixat",
        "outputId": "bf220a7e-d048-429d-ea9e-a3ed6b9d2b8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [1, 2],\n",
              "        [2, 3]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a+b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGbqsZmRI2s8"
      },
      "source": [
        "## Indexación y slicing\n",
        "Así como en un arreglo en Python, se puede acceder a los elementos de un tensor por índice, teniendo el primer elemento un índice 0. Así como en las listas, el último elemento se puede acceder a él mediante el -1, y así para las demás posiciones.\n",
        "[1:3] selecciona el segundo y tercer elemento, el elemento de la posición 4 no se incluye.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oj7qykiIK0qm",
        "outputId": "98a494e4-c521-4b6c-acd4-e1d82a9ab835"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 8.,  9., 10., 11.]), tensor([[ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.]]))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[-1], X[1:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LnQc-0dLR8u"
      },
      "source": [
        "Se puede escribir elementos en una matriz mediante los índices:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zazaTkx1LWO-",
        "outputId": "c0b3de15-f8a9-4b59-da4f-798a3630b215"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5.,  9.,  7.],\n",
              "        [ 8.,  9., 10., 11.]])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[1,2] = 9\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5aPH2HdL_8t"
      },
      "source": [
        "Si queremos asignar a varios elementos el mismo valor, se indexan los que se desean, tal como en un array.\n",
        "Por ejemplo: [0:2,:] accede a la primera y segunda fila, y con : nos indica que toma todas las columnas. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoAiZHSZMyv9",
        "outputId": "4942f156-751f-4bb8-ecd9-f3e8aaa396a4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[12., 12., 12., 12.],\n",
              "        [12., 12., 12., 12.],\n",
              "        [ 8.,  9., 10., 11.]])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0:2, :] = 12\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pNNKIzHM2R1"
      },
      "source": [
        "## Guardar la memoria\n",
        "Cuando ejecutamos operaciones puede ocurrir que se asigne nueva memoria a los resultados, aún cuando se asignen a la propia variable.\n",
        "\n",
        "Por ejemplo, si se realiza la operaciones Y = X+Y, lo que ocurre es que ya no se referencía el tensor al que apuntaba Y, sino que ahora se apunta Y a la memoria recién asignada. Esto se observa a continuación, con la función __id()__ de Python, nos da la dirección exacta del objeto referenciado en memoria.\n",
        "Si se ejecuta Y = Y+X, nos arrojará que id(Y) ahora apunta a una dirección diferente,  debido a que primero se evalúa Y+X, asignando nueva memoria para el resultado y luego hace que Y apunte a esta nueva dirección en memoria.\n",
        "Es por esto que el siguiente código da False.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smEwoA-3SYXy",
        "outputId": "f129516e-ef4a-4c6e-ca68-fc0d55fe4e5a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "before = id(Y)\n",
        "Y = Y + X\n",
        "id(Y) == before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGvgHyFwSag5"
      },
      "source": [
        "Esto puede ser indeseable por dos razones. Primero, porque no se quiere estar asignando memoria innecesaria cada vez, sino que es deseable que se realicen las actualizaciones en el mismo lugar. Segundo, porque al tener cientos de megabytes de parámetros en ciertos proyectos, podríamos apuntar a los mismos parámetros desde múltiples variables.\n",
        "\n",
        "No obstante, realizar operaciones en el mismo lugar es sencillo. Podemos asignar el resultado de una operación a una matriz previamente asignada con la notación slice, por ejemplo: Y[:] = <expresión>. \n",
        "Para realizar esto, primero creamos una matriz nueva Z con la misma forma que Y, utilizando la función __zeros_like__ para asignar un bloque de 0 entradas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF7Z2SZeUzvp",
        "outputId": "b501e0e2-bb05-4ca4-dbd4-450d98dc16c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0.]])\n",
            "id(Z): 140154347304144\n",
            "id(Z): 140154347304144\n"
          ]
        }
      ],
      "source": [
        "Z = torch.zeros_like(Y)\n",
        "print(Z)\n",
        "print('id(Z):', id(Z))\n",
        "Z[:] = X + Y\n",
        "print('id(Z):', id(Z))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsdMmzGwVHd3"
      },
      "source": [
        "Ahora bien, si el valor de X no se utiliza más adelante, tambien se puede utilizar lo siguiente; X[:] = X+Y, o, X+=Y para reducir la sobrecarga de memoria de la operación. En el código siguiente se observa que funciona correctamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9fWQ7zbVbcB",
        "outputId": "a1d13ebf-0680-434e-9f4a-d2ccf36cc813"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "before = id(X)\n",
        "X += Y\n",
        "id(X) == before"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNG3iTgpVhkQ"
      },
      "source": [
        "## Conversión a otros objetos de Python\n",
        "**Convertir a un tensor NumPy**\n",
        "\n",
        "El tensor de torch y el array de Numpy compartirán ubicaciones de memoria subyacentes, y el cambio de uno a través de una operación in-place también cambiará el otro."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fszv2vyYnTh",
        "outputId": "54f35781-d9e8-4a66-b820-c61ba16d4a9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(numpy.ndarray, torch.Tensor)"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = X.numpy()\n",
        "B = torch.from_numpy(A)\n",
        "type(A), type(B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y6qq0B2Y1Aa"
      },
      "source": [
        "Para convertir un tensor de tamaño 1 en un escalar de python, podemos usar la función __item__ o funciones incorporadas en Python como float o int.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNZUh7-sZCRB",
        "outputId": "a43e1571-8a15-4faf-ca18-348d0184fcd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([3.5000]), 3.5, 3.5, 3)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = torch.tensor([3.5])\n",
        "a,a.item(),float(a),int(a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSkgIW9HZVGC"
      },
      "source": [
        "# Preprocesamiento de datos\n",
        "El paqueta pandas es una de las herramientas populares de análisis de datos en Python. Pandas puede trabajar con tensores.\n",
        "Para aplicar el aprendizaje profundo a la resolución de problemas, se comienza con un preprocesamiento de datos en bruto, en vez de aquellos datos bien preparados en el formato de tensor. Por esto, con pandas se hace el preprocesamiento para de ahí convertirlos en el formato tensor.\n",
        "\n",
        "## Lectura del conjunto de datos\n",
        "Se comenzará creando un conjunto de datos artificial que se almacena en un archivo csv: ./data/house_tiny.csv.\n",
        "\n",
        "Se escribira el conjunto de datos fila por fila en un archivo csv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZy7ajmrcyHM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
        "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
        "with open(data_file, 'w') as f:\n",
        "  f.write('NumRooms,Alley,Price\\n')  # Nombre de las columnas\n",
        "  f.write('NA,Pave,127500\\n')  # Cada fila representa un ejemplo de datos\n",
        "  f.write('2,NA,106000\\n')\n",
        "  f.write('4,NA,178100\\n')\n",
        "  f.write('NA,NA,140000\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru7ZZrdHdMQz"
      },
      "source": [
        "Para cargar el conjunto de datos en bruto desde el archivo csv que se creó, se importa el paquete pandas y se utiliza su función _read_csv_.\n",
        "\n",
        "El conjunto de datos tiene 4 filas y 3 columnas, en donde cada fila describe el número de habitaciones (\"NumRooms\"), el tipo de callejón (\"Alley\") y el precio (\"Price\") de una casa, tal como se observó en el código anterior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvm4aZC-dpyc",
        "outputId": "4ee4c6f2-54cc-4355-aef2-34e0dc1eafc0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas # instalación de pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX-0r2PSdukJ",
        "outputId": "f1002cf1-a492-4e51-dab7-9f4d31786ac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   NumRooms Alley   Price\n",
            "0       NaN  Pave  127500\n",
            "1       2.0   NaN  106000\n",
            "2       4.0   NaN  178100\n",
            "3       NaN   NaN  140000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(data_file)\n",
        "\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PX77w8eyeAa9"
      },
      "source": [
        "## Tratamiento de datos faltantes\n",
        "Los valores NaN que se observan, son valores perdidos. Para tratar a estos datos, los métodos típicos son la imputación y la eliminación, donde la imputación sustituye los valores que faltan por otros sustituidos, y la eliminación ignora los valores que faltan.\n",
        "\n",
        "Considerando la imputación, tenemos:\n",
        "Mediante la indexación basada en la localización de enteros (iloc), dividimos los datos en entradas y salidas, siendo las entradas las dos primeras columnas y la salida la última columna. Para los valores que faltan, se sustituye en NaN por el valor medio de su columna correspondiente. Esto se realiza de la siguiente forma:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H016Ivdl3QN",
        "outputId": "729b77b0-e1fc-4ed1-9eeb-8604159bf870"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   NumRooms Alley\n",
            "0       3.0  Pave\n",
            "1       2.0   NaN\n",
            "2       4.0   NaN\n",
            "3       3.0   NaN\n"
          ]
        }
      ],
      "source": [
        "inputs,outputs = data.iloc[:,0:2], data.iloc[:,2]\n",
        "inputs = inputs.fillna(inputs.mean()) # sustituye NaN por valor medio de la columna\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POzanLtamPzJ"
      },
      "source": [
        "Para los valores categóricos o discretos en las entradas, consideraremos NaN como una categoría. De este modo, Alley está contituido de Pave y NaN, con esto, pandas puede convertir automáticamente esta columna en dos columnas, una con el nombre \"Alley_Pave\" y la otra con \"Alley_nan\". Una fila cuya tipo de callejón sea \"Pave\" establecerá los valores de \"Alley_Pave\" y \"Alley_nan\" a 1, y 0. Una fila con tipo de callejon ausente, establecerá los valores 0 y 1. Esto se puede apreciar en el siguiente código:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQ62r4LlnQKg",
        "outputId": "7ba565e2-3466-4fc5-e3f3-36b3d355c71f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   NumRooms  Alley_Pave  Alley_nan\n",
            "0       3.0           1          0\n",
            "1       2.0           0          1\n",
            "2       4.0           0          1\n",
            "3       3.0           0          1\n"
          ]
        }
      ],
      "source": [
        "inputs = pd.get_dummies(inputs,dummy_na = True)\n",
        "print(inputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyBAmK3Knbdu"
      },
      "source": [
        "## Conversión al formato Tensor\n",
        "Como todas las entradas y salidas son numéricas, se puede convertir al formato Tensor. Cuando estén en dicho formato, ya pueden ser manipulados con las funciones de los tensores.\n",
        "\n",
        "X: Entradas\n",
        "y: Salidas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4UpCwcNn2tR",
        "outputId": "896e1b5e-0d92-416a-a22d-36b7d45cd886"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[3., 1., 0.],\n",
              "         [2., 0., 1.],\n",
              "         [4., 0., 1.],\n",
              "         [3., 0., 1.]], dtype=torch.float64),\n",
              " tensor([127500, 106000, 178100, 140000]))"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)\n",
        "X,y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzke6lHQ3zEW"
      },
      "source": [
        "# Algebra lineal\n",
        "\n",
        "## Escalares\n",
        "Valores que constan de una sola cantidad numérica.\n",
        "\n",
        "Si queremos convertir grados Fahrenheit a Celsius, se usa la siguiente expresión: $c = \\frac{5}{9}(f-32)$, donde $\\frac{5}{9}$  y 32 son escalares. Las letras $c$ y $f$ representan valores escalares desconocidos.\n",
        "\n",
        "Las variables se denotan por letras en minúsculas en este apartado. $\\mathbb R$ denota el espacio de todos los escalares de valor real.\n",
        "\n",
        "$x \\in \\mathbb R$ es una forma de decir que $x$ es un escalar de valor real.\n",
        "\n",
        "Un escalar es representado por un tensor con un solo elemento.\n",
        "\n",
        "A continuación, se muestran 2 escalares y se realizan operaciones aritméticas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p2YbJMFp6KFU",
        "outputId": "54e7b20b-4821-44b3-e27b-fd5d9daeabe4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(5.)\n",
            "tensor(6.)\n",
            "tensor(1.5000)\n",
            "tensor(9.)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "x = torch.tensor(3.0)\n",
        "y = torch.tensor(2.0)\n",
        "print(x+y) # suma\n",
        "print(x*y) # multiplicación\n",
        "print(x/y) # división\n",
        "print(x**y) # exponenciación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH0tmknI6iDq"
      },
      "source": [
        "## Vectores\n",
        "Se puede pensar un vector como una simple lista de valores escalares. Estos serán llamados elementos (entradas o componentes) del vector.\n",
        "\n",
        "En la notación matemática, se suele denotar a los vectores con letras minúsculas y en negrita: **x**,**y** y **z**.\n",
        "\n",
        "Los vectores son tensores unidimensionales, de longitudes arbitrarias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToMbW-kl7s8k",
        "outputId": "93a5ca1a-1f9c-43de-904f-060985fd1037"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(4)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSpuF7IR7yt5"
      },
      "source": [
        "Podemos referirnos al i-ésimo elemento de **x** mediante $x_i$, siendo $x_i$ un escalar.\n",
        "En la literatura, por defecto a los vectores se consideran como vectores columnas.\n",
        "\n",
        "\\begin{equation}\n",
        "x =\\begin{pmatrix}\n",
        "x_1 \\\\\n",
        "x_2 \\\\\n",
        "\\vdots \\\\\n",
        "x_n \n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70iMqrQl8bIM"
      },
      "source": [
        "donde $x_1,...,x_n$ son elementos del vector, y accedemos a cada elemento mediante indexación en el tensor:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pExt1vyY8lWH",
        "outputId": "722720dc-a8f2-4ce5-b35c-1e12e9ce5a5f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x[3] # elemento 4 del vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzXafDSZ8spa"
      },
      "source": [
        "## **Longitud, dimensionalidad y forma**\n",
        "Un vector es un arreglo de números. Cada vector tiene una longitud.\n",
        "\n",
        "En notación matemática, si queremos decir que un vector **x** consiste de $n$ escalares de valor real, se puede expresar como **x** $\\in \\mathbb R^n$.\n",
        "\n",
        "La longitud del vector se llama comúnmente como la dimensión del vector.\n",
        "\n",
        "Podemos saber la longitud de un tensor mediante la función _len_.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sLqKoOwx9Ws9",
        "outputId": "a28b2e27-e7fc-4646-ab2c-bdc5ad4fa2c0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(x) # longitud o dimensión de x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vHA3P0O9lZa"
      },
      "source": [
        "Cuando un tensor representa un vector, se puede obtener su longitud al obtener su atributo de forma con _.shape_. La forma es una tupla que enlista la longitud a lo largo de cada eje del tensor, y al hablar de un vector, nos arroja su longitud:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCE7pL8h93Qj",
        "outputId": "75e8c624-1154-42b9-b85c-d3eb0e9b08d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NOhl7oo-STS"
      },
      "source": [
        "## Matrices\n",
        "Las matrices generalizan vectores de orden 1 a orden 2.\n",
        "Se denotan típicamente con letras mayúsculas: **X**, **Y** y **Z**.\n",
        "En código se representan como tensores con 2 ejes.\n",
        "\n",
        "En notación matemática, se usa **A** $\\in \\mathbb R^{m \\times n}$ para expresar que la matriz **A** consiste de $m$ filas y de $n$ columnas de escalares de valor real.\n",
        "\n",
        "Se puede ver como una tabla donde cada elemento $a_{ij}$ pertenece a la i-ésima fila y j-ésima columna.\n",
        "\n",
        "\\begin{equation}\n",
        "A =\\begin{pmatrix}\n",
        "a_{11} & a_{12} & \\cdots & a_{1n}\\\\\n",
        "a_{21} & a_{22} & \\cdots & a_{2n}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "a_{m1} & a_{m2} & \\cdots & a_{mn}\n",
        "\\end{pmatrix}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRkdmJvy_RAV"
      },
      "source": [
        "Si $m = n$ se dice que la matriz es cuadrada.\n",
        "\n",
        "Para crear una matriz tenemos que especificar la forma con dos componentes, tal y como se muestra:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2yk-Ppr_nQb",
        "outputId": "72e84099-72ab-4952-844f-1da3218aae47"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  1,  2,  3],\n",
              "        [ 4,  5,  6,  7],\n",
              "        [ 8,  9, 10, 11],\n",
              "        [12, 13, 14, 15],\n",
              "        [16, 17, 18, 19]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = torch.arange(20).reshape(5,4)\n",
        "A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFuoTeuS_6da"
      },
      "source": [
        "Podemos acceder al elemento $a_{ij}$ de la matriz A, especificando los índices de las filas (i) y columnas (j), tal como $[\\textbf{A}]_{i,j}$ \n",
        "\n",
        "**Transpuesta de una matriz**\n",
        "\n",
        "La transpuesta de una matriz es cuando se intercambian filas por columnas de la matriz y se denota por $\\textbf{A}^{T}$, y si tenemos que $\\textbf{B} = \\textbf{A}^{T}$, entonces $b_{ij} = a_{ji}$, para cualquier $i$ y $j$.\n",
        "\n",
        "\\begin{equation}\n",
        "A ^T=\\begin{pmatrix}\n",
        "a_{11} & a_{21} & \\cdots & a_{m1}\\\\\n",
        "a_{12} & a_{22} & \\cdots & a_{m2}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "a_{1n} & a_{2n} & \\cdots & a_{mn}\n",
        "\\end{pmatrix}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m0RkNlkB4Xx",
        "outputId": "416a318c-8b8e-44dd-bc69-6ec949bbcd3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  4,  8, 12, 16],\n",
              "        [ 1,  5,  9, 13, 17],\n",
              "        [ 2,  6, 10, 14, 18],\n",
              "        [ 3,  7, 11, 15, 19]])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.T # transpuesta de una matriz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9ekTOflCIxC"
      },
      "source": [
        "**Matriz simétrica**\n",
        "\n",
        "Una matriz es simétrica si es igual a su transpuesta.\n",
        "$\\textbf{A} = \\textbf{A}^{T}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6iKLX6fCSQU"
      },
      "outputs": [],
      "source": [
        "B = torch.tensor([[1,2,3],[2,0,4],[3,4,5]]) # B es una matriz simétrica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTusSdQoC2Lw",
        "outputId": "909f79e7-9f8a-4a88-9200-6af17d3621ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "B == B.T # se iguala con su transpuesta y debe dar todos verdaderos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OViB2hdlDUCT"
      },
      "source": [
        "## Tensores\n",
        "Los tensores nos dan una forma genérica de describir a los arreglos n-dimensionales con un número arbitrario de ejes.\n",
        "\n",
        "Los vectores son tensores de primer orden, las matrices son tensores de segundo orden. Los tensores se denotan por letras mayusculas y un tipo de letras especial, y su mecanismo de indexación es similar al de matrices.\n",
        "\n",
        "Cuando se trabaja con imágenes los tensores tienen una gran importancia, ya que éstas llegan como arreglos n-dimensionales con 3 ejes correspondientes a la altura, anchura y un eje de canal para apilar los canales de color (rojo, verde y azul). \n",
        "\n",
        "Ejemplo de tensor:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fandnYY4G6C-",
        "outputId": "71328b97-4c70-4d6d-b119-0277a78f8502"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11]],\n",
              "\n",
              "        [[12, 13, 14, 15],\n",
              "         [16, 17, 18, 19],\n",
              "         [20, 21, 22, 23]]])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = torch.arange(24).reshape(2,3,4)\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZkBxtvpHX_2"
      },
      "source": [
        "## Propiedades básicas aritmética tensorial\n",
        "Dados dos tensores de la misma forma, el resultado de cualquier operación elemental binaria será un tensor con la misma forma, por ejemplo, si se suman dos matrices de la misma forma, se realiza una suma elemental sobre estas dos matrices.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcHO5rpHIGD5",
        "outputId": "df5c67d8-8d49-468a-b860-5a4f60aa34ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [12., 13., 14., 15.],\n",
              "         [16., 17., 18., 19.]]), tensor([[ 0.,  2.,  4.,  6.],\n",
              "         [ 8., 10., 12., 14.],\n",
              "         [16., 18., 20., 22.],\n",
              "         [24., 26., 28., 30.],\n",
              "         [32., 34., 36., 38.]]))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A = torch.arange(20,dtype=torch.float32).reshape(5,4)\n",
        "B = A.clone() # asigna una copia de A a B asignando nueva memoria\n",
        "A,A+B"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJQIhxekJyoz"
      },
      "source": [
        "La multiplicación elemental de dos matrices de denomina producto Hadamard (en notación matemática $\\odot$).\n",
        "\n",
        "Si tenemos una matriz $\\textbf{B} \\in \\mathbb R^{m\\times n}$, con los elementos de filas $i$ y columnas $j$ como $b_{ij}$. El producto Hadamard de matrices $\\textbf{A}$ y $\\textbf{B}$, se encuentra definida como:\n",
        "\n",
        "\\begin{equation}\n",
        "A \\odot B = \\begin{pmatrix}\n",
        "a_{11}b_{11} & a_{12}b_{12} & \\cdots & a_{1n}b_{1n}\\\\\n",
        "a_{21}b_{21} & a_{22}b_{22} & \\cdots & a_{2n}b_{2n}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "a_{m1}b_{m1} & a_{m2}b_{m2} & \\cdots & a_{mn}b_{mn}\n",
        "\\end{pmatrix}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyTe4YrgMQjP",
        "outputId": "da2f9279-229e-4c02-ba27-8150415c1d89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[  0.,   1.,   4.,   9.],\n",
              "        [ 16.,  25.,  36.,  49.],\n",
              "        [ 64.,  81., 100., 121.],\n",
              "        [144., 169., 196., 225.],\n",
              "        [256., 289., 324., 361.]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A*B # producto Hadamard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH2IQJVAMZSE"
      },
      "source": [
        "Multiplicar o sumar un tensor por un escalar, tampoco cambia la forma del tensor. Cada elemento del tensor será sumado o multiplicado por el escalar.\n",
        "\n",
        "En el siguiente código se suma un 2 al tensor X y también se multiplica por 2 al tensor X."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqL7QI5VMv21",
        "outputId": "c624a268-a1d8-4031-d4bb-030588f04ade"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([[[ 2,  3,  4,  5],\n",
              "          [ 6,  7,  8,  9],\n",
              "          [10, 11, 12, 13]],\n",
              " \n",
              "         [[14, 15, 16, 17],\n",
              "          [18, 19, 20, 21],\n",
              "          [22, 23, 24, 25]]]), torch.Size([2, 3, 4]))"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a = 2\n",
        "X = torch.arange(24).reshape(2, 3, 4)\n",
        "a + X, (a * X).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1HKQD0WM3yd"
      },
      "source": [
        "## Reducción\n",
        "Una operación útil que se puede realizar con tensores es calcular la suma de sus elementos. En código basta con llamar a la función para calcular la suma:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhMyIFpURNMV",
        "outputId": "78d90fd6-93cf-456a-83cb-f834e0d6ff2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2., 3.]), tensor(6.))"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(4,dtype = torch.float32)\n",
        "x,x.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqUlzOIqSHLq"
      },
      "source": [
        "Podemos expresar sumas sobre los elementos de tensores de forma arbitrarria.\n",
        "Por ejemplo, la suma de los elementos de una matriz $\\textbf{A}$ de $m \\times n$ se puede escribir como:\n",
        "\n",
        "$\\sum_{i = 1}^{m}\\sum_{j = 1}^{n}a_{ij}$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M4DD5hwoSlf7",
        "outputId": "fd1af828-652d-4cf8-acba-24d91762513c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [ 8.,  9., 10., 11.],\n",
              "        [12., 13., 14., 15.],\n",
              "        [16., 17., 18., 19.]])"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.shape, A.sum()\n",
        "A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkOlOdhpTEh4"
      },
      "source": [
        "Por defecto, la suma reduce un tensor a lo largo de todos sus ejes a un escalar, no obstante, podemos especificiar los ejes a lo largo de los cuales se reduce el tensor mediante la suma.\n",
        "\n",
        "Si usamos las matrices como ejemplo, y reducimos la dimensión de la fila (eje 0) sumando los elementos de todas las filas, especificamos eje = 0 al llamar a la función.\n",
        "\n",
        "Al realizar esto, se sumaría la primer columna y se colocaría el resultado en el primer elemento del eje 0, para la segunda columna es lo mismo, colocándose el resultado en el segundo elemento del eje 0. Esto se puede ver a continuación:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYa3IXSeUjfN",
        "outputId": "c96f566c-bf20-40fb-8835-d49d3f64f972"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([40., 45., 50., 55.]), torch.Size([4]))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A_sum_axis0 = A.sum(axis=0)\n",
        "A_sum_axis0, A_sum_axis0.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDaHsE0VU21a"
      },
      "source": [
        "En cambio, si se coloca como parámetro al eje 1, se hace la suma por filas (se suman los elementos de la fila 1, de la fila 2, así sucesivamente), es decir, sumando los elementos de las columnas.\n",
        "\n",
        "Con el ejemplo que se ha utilizado resulta lo siguiente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kdx2Km7XVLrc",
        "outputId": "2cbda2c2-c195-44e3-e74e-8bf5ba1bf5bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A_sum_axis1 = A.sum(axis=1)\n",
        "A_sum_axis1, A_sum_axis1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yT1099JGVPmc"
      },
      "source": [
        "Si reducimos la matriz a lo largo de las filas y columnas es equivalente a sumar todos los elementos de la matriz:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe_NWJZ9VVD6",
        "outputId": "7c2be998-f0ea-4148-ab58-37e393ebc1e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(190.)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.sum(axis=[0, 1]) # esto es igual a A.sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acHp5Lh3Vbxx"
      },
      "source": [
        "Una cantidad relacionada es la media o promedio. Esto se obtiene dividiendo la suma entre el número total de elementos. Mediante código resulta:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcFdgqHoVmE-",
        "outputId": "e93bf3a8-2679-4f00-8971-0751b9693a37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor(9.5000), tensor(9.5000))"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.mean(), A.sum() / A.numel() # se puede realizar de ambas formas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8egASrr8VvIh"
      },
      "source": [
        "La media también puede reducir el tensor a lo largo de los ejes especificados, como ocurría con la suma:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3jI59_WV3ak",
        "outputId": "26074078-d6e9-4108-9c03-7d59a2f96bf0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.mean(axis=0), A.sum(axis=0) / A.shape[0] # se puede hacer de ambas formas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qo6ab4G4WAgf"
      },
      "source": [
        "### **Suma sin reducción**\n",
        "A veces se puede mantener el número de ejes sin cambios cuando se llama a la función suma o media, mediante el parámetro _keepdims = True_.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao47t7GhW66w",
        "outputId": "269adcd7-8c98-41cf-89c2-de5e6dd7bd40"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 6.],\n",
              "        [22.],\n",
              "        [38.],\n",
              "        [54.],\n",
              "        [70.]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sum_A = A.sum(axis=1, keepdims=True)\n",
        "sum_A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3ZfPVPsXIWb"
      },
      "source": [
        "Como la sum_A sigue conservando sus dos ejes después de sumar cada fila, se puede dividir A entre la sum_A mediante difusión:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3wathT4XRQZ",
        "outputId": "968a8b46-9ae4-4428-ae9c-b5c1694a7d7d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.1667, 0.3333, 0.5000],\n",
              "        [0.1818, 0.2273, 0.2727, 0.3182],\n",
              "        [0.2105, 0.2368, 0.2632, 0.2895],\n",
              "        [0.2222, 0.2407, 0.2593, 0.2778],\n",
              "        [0.2286, 0.2429, 0.2571, 0.2714]])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A/sum_A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xhX7T2IXarp"
      },
      "source": [
        "Si queremos calcular la suma acumulativa de elementos de A a lo largo de algún eje, podemos llamar a la función _cumsum_, es decir, se conserva la forma de la matriz pero en los ejes se va poniendo la suma en base a si es con respecto a las filas o a las columnas. Esto se observa en lo siguiente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26Gs0Iz1XwOS",
        "outputId": "12623a35-8146-490d-c56d-60caa17d000e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  6.,  8., 10.],\n",
              "        [12., 15., 18., 21.],\n",
              "        [24., 28., 32., 36.],\n",
              "        [40., 45., 50., 55.]])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.cumsum(axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wK8gRgfxX2gy"
      },
      "source": [
        "## Productos puntos\n",
        "Dados dos vectores $\\textbf{x}$ y $\\textbf{y} \\in \\mathbb R^d$, su producto punto denotado por $\\textbf{x}^T\\textbf{y}$ ó $⟨\\textbf{x},\\textbf{y}⟩$, es una suma sobre los productos de los elementos en la misma posición, es decir, se multiplica el elemento 1 de un vector con el elemento 1 del otro, y así con todos los elementos y finalmente se hace la suma; en notación matemática es:\n",
        "$\\textbf{x}^T\\textbf{y} = \\sum_{i=1}^d x_iy_i$:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8Xs_KeZZVMh",
        "outputId": "ba36440d-ee24-43dd-93d8-36f672a6176c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2., 3.]), tensor([1., 1., 1., 1.]), tensor(6.))"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.arange(4, dtype=torch.float32) # vector x\n",
        "y = torch.ones(4,dtype = torch.float32) # vector y\n",
        "x, y, torch.dot(x, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j_arCtGZ0bE"
      },
      "source": [
        "El producto punto se puede expresar mediante la multiplicación po elementos y luego la suma, en lugar de usar _dot_:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6UbafrlZ_d7",
        "outputId": "81d61f97-1839-4348-bbdd-a8b71478f2db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.sum(x * y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlLCNGZilqbz"
      },
      "source": [
        "El producto punto expresa una media ponderada. \n",
        "\n",
        "Si tenemos dos vectores normalizados (su magnitud es la unidad), el producto punto entre ellos expresan el coseno del ángulo entre ellos.\n",
        "\n",
        "## Productos Matriz-Vector\n",
        "Una matriz $\\textbf{A}$ en términos de sus vectores fila se visualiza como\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{A}   = \\begin{pmatrix}\n",
        "\\textbf{a}_1^T\\\\\n",
        "\\textbf{a}_2^T \\\\\n",
        "\\vdots \\\\\n",
        "\\textbf{a}_m^T\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "donde cada $\\textbf{a}_1^T \\in \\mathbb R^n$ es un vector fila que representa la i-ésima fila de la matriz $\\textbf{A}$.\n",
        "\n",
        "El producto matriz-vector $\\textbf{A}\\textbf{x}$ es un simple vector columna de longitud $m$, cuyo i-ésimo elemento es el producto punto $\\textbf{a}_1^T\\textbf{x}$:\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{Ax}  = \\begin{pmatrix}\n",
        "\\textbf{a}_1^T\\textbf{x}\\\\\n",
        "\\textbf{a}_2^T\\textbf{x} \\\\\n",
        "\\vdots \\\\\n",
        "\\textbf{a}_m^T\\textbf{x}\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Podemos pensar a la multiplicación por una matriz $\\textbf{A}$ como una transformación que proyecta vectores de $\\mathbb R^n$ a $\\mathbb R^m$.\n",
        "\n",
        "\n",
        "Para expresar los productos matriz-vector con tensores se utiliza la función _mv_. La dimensión de la columna de la matriz $\\textbf{A}$ (longitud a lo largo del eje 1), tiene que ser igual a la dimensión del vector $\\textbf{x}$:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FayfRaJ044lj",
        "outputId": "af32c091-f104-459c-d13b-31466f8c2bc1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.shape, x.shape, torch.mv(A, x) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0X_7lZ3n4_Ai"
      },
      "source": [
        "## Multiplicación Matriz-Matriz\n",
        "Se tiene a las dos matrices $\\textbf{A} \\in \\mathbb R^{n \\times k}$ y $\\textbf{B} \\in \\mathbb R^{k \\times m}$, definidas como:\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{A} = \\begin{pmatrix}\n",
        "a_{11} & a_{12} & \\cdots & a_{1k}\\\\\n",
        "a_{21} & a_{22} & \\cdots & a_{2k}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "a_{n1} & a_{n2} & \\cdots & a_{nk}\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{B} = \\begin{pmatrix}\n",
        "b_{11} & b_{12} & \\cdots & b_{1m}\\\\\n",
        "b_{21} & b_{22} & \\cdots & b_{2m}\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "b_{k1} & b_{k2} & \\cdots & b_{nm}\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "Denotamos como $\\textbf{a}_i^T \\in \\mathbb R^k$ al vector fila que representa la i-ésima fila de la matriz $\\textbf{A}$ y $\\textbf{b}_j^T \\in \\mathbb R^k$ al vector columna de la j-ésima columna de la matriz $\\textbf{B}$. \n",
        "\n",
        "Para producir el producto matricial $\\textbf{C} = \\textbf{AB}$, se piensan a las matrices $\\textbf{A}$ y $\\textbf{B}$ en términos de vectores fila, y columna, respectivamente:\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{A}  = \\begin{pmatrix}\n",
        "\\textbf{a}_1^T\\\\\n",
        "\\textbf{a}_2^T \\\\\n",
        "\\vdots \\\\\n",
        "\\textbf{a}_n^T\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{B}  = \\begin{pmatrix}\n",
        "\\textbf{b}_1 & \\textbf{b}_2 & \\cdots & \\textbf{b}_m\\\\\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "La matriz resultante $\\textbf{C} \\int \\mathbb R^{n \\times m}$ se produce calculando cada elemento $c_{ij}$ mediante el producto punto $\\textbf{a}_i^T\\textbf{b}_j$\n",
        "\n",
        "\n",
        "\\begin{equation}\n",
        "\\textbf{C}  = \\textbf{AB} = \\begin{pmatrix}\n",
        "\\textbf{a}_1^T\\\\\n",
        "\\textbf{a}_2^T \\\\\n",
        "\\vdots \\\\\n",
        "\\textbf{a}_n^T\\end{pmatrix}\\begin{pmatrix}\n",
        "\\textbf{b}_1 & \\textbf{b}_2 & \\cdots & \\textbf{b}_m\\\\\n",
        "\\end{pmatrix} = \\begin{pmatrix}\n",
        "\\textbf{a}_1^T\\textbf{b}_1 & \\textbf{a}_1^T\\textbf{b}_2 & \\cdots & \\textbf{a}_1^T\\textbf{b}_m\\\\\n",
        "\\textbf{a}_2^T\\textbf{b}_1 & \\textbf{a}_2^T\\textbf{b}_2 & \\cdots & \\textbf{a}_2^T\\textbf{b}_m\\\\\n",
        "\\vdots & \\vdots & \\ddots & \\vdots\\\\\n",
        "\\textbf{a}_n^T\\textbf{b}_1 & \\textbf{a}_n^T\\textbf{b}_2 & \\cdots & \\textbf{a}_n^T\\textbf{b}_m\n",
        "\\end{pmatrix}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "En esta multiplicación, si la primera matriz tiene dimensión ($n,k$) y la segunda tiene dimensión ($k,m$), vemos que la primer matriz debe tener las mismas columnas que filas la segunda matriz. El resultado tendrá una dimensión igual a los extremos de las dos matrices multiplicadas, es decir, ($n,m$).\n",
        "\n",
        "En código se utiliza la función _mm_. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOutPtLm9nr2",
        "outputId": "c3350416-3593-4df3-e238-7ae1674b07e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 6.,  6.,  6.],\n",
              "        [22., 22., 22.],\n",
              "        [38., 38., 38.],\n",
              "        [54., 54., 54.],\n",
              "        [70., 70., 70.]])"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "B = torch.ones(4, 3)\n",
        "torch.mm(A, B)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuBd0jna92SW"
      },
      "source": [
        "## Norma\n",
        "La norma nos indica el tamaño de un vector, siendo aquí referente a la magnitud de los componentes y no a su dimensionalidad.\n",
        "\n",
        "Una norma vectorial es una función $f$ que mapea un vector a un escalar satisfaciendo diversas propiedades.\n",
        "\n",
        "**Propiedades**\\\n",
        "Dado cualquier vector $\\textbf{x}$:\n",
        "\n",
        "* Si se escalan todos los elementos del vector por un factor constante $\\alpha$, la norma también se escala por el valor absoluto del mismo factor constante:\n",
        "\n",
        "$f(\\alpha\\textbf{x}) = |\\alpha|f(\\textbf{x})$\n",
        "\n",
        "* Desigualdad del triangulo:\n",
        "\n",
        "$f(\\textbf{x}+\\textbf{y}) \\leq f(\\textbf{x}) + f(\\textbf{y})$\n",
        "\n",
        "* La norma debe no debe ser negativa:\n",
        "\n",
        "$f(\\textbf{x}) \\geq 0$\n",
        "\n",
        "* La norma más pequeña se obtiene sólo si el vector consiste de puros ceros:\n",
        "\n",
        "$\\forall_i ,[\\textbf{x}_i]$ = 0 $↔ f(\\textbf{x}) = 0$\n",
        "\n",
        "\n",
        "La distancia euclidea es una norma, es la norma **$L_2$**:\n",
        "\n",
        "La norma **$L_2$** de $\\textbf{x}$ es la raíz cuadrada de la suma de los cuadrados de los elementos del vector:\n",
        "\n",
        "$∥\\textbf{x}∥_2 = \\sqrt{\\sum_{i = 1}^n x_i^2}$\n",
        "\n",
        "La norma **$L_2$** se puede calcular en código mediante:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZYGyfZSEZJE",
        "outputId": "6ad52784-03a2-43b3-ba98-4cc630420d2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "u = torch.tensor([3.0, -4.0])\n",
        "torch.norm(u) # norma L2 del vector u"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBAPAqebE58M"
      },
      "source": [
        "La norma **$L_1$** también es frecuente, y se expresa como la suma de los valores absolutos de los elementos del vector:\n",
        "\n",
        "$∥\\textbf{x}∥_1 = \\sum_{i = 1}^n |x_i|$\n",
        "\n",
        "Para calcular esta norma mediante código, se compone la función de valor absoluto con la suma de los elementos:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-clBUVXFh0N",
        "outputId": "9a02da0e-2727-4a99-f118-04e0d798de52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.abs(u).sum() # norma L1 del vector u\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFHpBnkkFoRk"
      },
      "source": [
        "Estas dos normas, son casos especiales de la norma **$L_p$** más general:\n",
        "\n",
        "$∥\\textbf{x}∥_p = (\\sum_{i = 1}^n |x_i|^p)^{\\frac{1}{p}}$\n",
        "\n",
        "Para el caso de matrices y similar a la norma **$L_2$**, la norma Frobenius de una matriz $\\textbf{X} \\in \\mathbb R^{m \\times n}$ es la raíz cuadrada de la suma de los cuadrados de los elementos de la matriz:\n",
        "\n",
        "$∥\\textbf{X}∥_F = \\sqrt{\\sum_{i = 1}^m\\sum_{j = 1}^n x_{ij}^2}$\n",
        "\n",
        "Esta norma satisface las propiedades de las normas vectoriales.\n",
        "\n",
        "Se calcula en código mediante:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wP2WZowGlpA",
        "outputId": "d43edcf2-4547-4c81-a228-dfbc832f1f73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.norm(torch.ones((4,9)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHdeQ1hsG5Rx"
      },
      "source": [
        "# Cálculo\n",
        "Las aplicaciones más críticas del cálculo diferencial son los problemas de optimización.\n",
        "\n",
        "En el aprendizaje profundo, se entrenan modelos actualizándolos para que mejoren conforme se ven más datos, mejorar hace referencia a minimizar una función de pérdida.\n",
        "\n",
        "Lo que importa es producir un modelo que funcione bien con datos que nunca hemos visto, pero ajustando el modelo a los datos que realmente vemos.\n",
        "\n",
        "El ajuste de modelos se puede dividir en dos aspectos clave:\n",
        "\n",
        "i) Optimización: proceso de ajuste de nuestros modelos a datos observados.\n",
        "\n",
        "ii) Generalización: principios matemáticos y conocimiento de profesionales que orientan sobre cómo producir modelos cuya validez se extiende más allá del conjunto exacto de ejemplos de datos utilizados para entrenarlos.\n",
        "\n",
        "## Diferenciación y derivadas\n",
        "\n",
        "En el aprendizaje automático, se eligen funciones de pérdida que son diferenciables respecto a parámetros del modelo, esto nos dice que podemos saber la rapidez con que aumentaría o disminuiría la pérdida si aumentáramos o disminuyéramos ese parámetros en una cantidad infinitesimal.\n",
        "\n",
        "Supongamos una función $f: \\mathbb R \\to \\mathbb R$, cuya entrada y salida son escalares. La derivada de $f$ se define como:\n",
        "\n",
        "$f'(x) = \\lim_{h \\to 0} \\frac{f(x+h)-f(x)}{h}$\n",
        "\n",
        "si el límite existe.\n",
        "\n",
        "Si $f'(a)$ existe, $f$ es diferenciable en $a$. Así mismo, si $f$ es diferenciable en cada número de un intervalo, entonces $f$ es diferenciable en este intervalo. La derivada la podemos interpretar como la tasa de cambio instantánea de $f(x)$ con respecto a $x$.\n",
        "\n",
        "\n",
        "Ejemplo:\n",
        "\n",
        "Tenemos la función $u = f(x) = 3x^2-4x$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mLNv6WpLKFU"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from IPython import display\n",
        "#from d2l import torch as d2l\n",
        "\n",
        "def f(x):\n",
        "  return 3*x**2-4*x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBPbosRHMIU6"
      },
      "source": [
        "Conforme h se acerca a 0, y estableciendo $x = 1$, la derivada va teniendo un valor igual a 2, esto se muestra a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1a3zC5SLbwG",
        "outputId": "cc0e43e2-0e19-47c9-f697-1b3f0d288422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "h = 0.10000, limite = 2.30000\n",
            "h = 0.01000, limite = 2.03000\n",
            "h = 0.00100, limite = 2.00300\n",
            "h = 0.00010, limite = 2.00030\n",
            "h = 0.00001, limite = 2.00003\n"
          ]
        }
      ],
      "source": [
        "def numerical_lim(f,x,h):\n",
        "  return (f(x+h)-f(x))/h # derivada de f\n",
        "\n",
        "h = 0.1\n",
        "\n",
        "for i in range(5):\n",
        "  print(f\"h = {h:.5f}, limite = {numerical_lim(f,1,h):.5f}\")\n",
        "  h *= 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWxC0bT2MUFu"
      },
      "source": [
        "**Expresiones equivalentes para la derivada**\n",
        "\n",
        "$f'(x) = y' = \\frac{dy}{dx} = \\frac{df}{dx} = \\frac{d}{dx}f(x) = Df(x) = D_xf(x)$\n",
        "\n",
        "los simbolos $\\frac{d}{dx}$ y $D$ son operadores de diferenciación.\n",
        "\n",
        "**Reglas para diferenciar funciones comunes:**\n",
        "\n",
        "* $DC = 0$ ($C$ es una constante)\n",
        "* $Dx^n = nx^{n-1}$ ($n$ cualquier número real)\n",
        "* $De^x = e^x$\n",
        "* $D$ln$(x)$ = $\\frac{1}{x}$\n",
        "\n",
        "**Reglas de derivación**\n",
        "\n",
        "$f$ y $g$ son funciones diferenciables y $C$ es una constante:\n",
        "\n",
        "\n",
        "* $\\frac{d}{dx}[Cf(x)] = C\\frac{d}{dx}f(x)$\n",
        "* Regla de la suma\n",
        "\n",
        "$\\frac{d}{dx}[f(x)+g(x)] = \\frac{d}{dx}f(x)+\\frac{d}{dx}g(x)$\n",
        "\n",
        "* Regla del producto\n",
        "\n",
        "$\\frac{d}{dx}[f(x)g(x)] = f(x)\\frac{d}{dx}[g(x)]+g(x)\\frac{d}{dx}[f(x)]$\n",
        "\n",
        "* Regla del cociente\n",
        "\n",
        "$\\frac{d}{dx}[\\frac{f(x)}{g(x)}] = \\frac{g(x)\\frac{d}{dx}[f(x)]-f(x)\\frac{d}{dx}[g(x)]}{[g(x)]^2}$\n",
        "\n",
        "Para visualizar la interpretación de las derivadas, se utilzará la librería matplotlib. Además, funciones como _use_svg_display_ especifica que el paquete matplotlib produzca las figuras svg para obtener imágenes más nítidas.\n",
        "\n",
        "Tenemos primero la siguiente función:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2D6i1VlMP78k"
      },
      "outputs": [],
      "source": [
        "def use_svg_display():  \n",
        "    \"\"\"Usa el formato svg para desplegar un gráfico en Jupyter.\"\"\"\n",
        "    display.set_matplotlib_formats('svg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYnGZhZSQHPA"
      },
      "source": [
        "Ahora se define la función set_figsize para especificar los tamaños de las figuras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5axuaZ1uQZai"
      },
      "outputs": [],
      "source": [
        "def set_figsize(figsize=(3.5, 2.5)):  \n",
        "    \"\"\"Set the figure size for matplotlib.\"\"\"\n",
        "    use_svg_display()\n",
        "    d2l.plt.rcParams['figure.figsize'] = figsize"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiCngB9wQ6Fc"
      },
      "source": [
        "La siguiente función set_axes establece las propiedades de los ejes de las figuras producidas por matplotlib.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2pylL7GRHKP"
      },
      "outputs": [],
      "source": [
        "def set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend):\n",
        "    \"\"\"Configura los ejes para matplotlib\"\"\"\n",
        "    axes.set_xlabel(xlabel)\n",
        "    axes.set_ylabel(ylabel)\n",
        "    axes.set_xscale(xscale)\n",
        "    axes.set_yscale(yscale)\n",
        "    axes.set_xlim(xlim)\n",
        "    axes.set_ylim(ylim)\n",
        "    if legend:\n",
        "        axes.legend(legend)\n",
        "    axes.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QStqeVlpRVMb"
      },
      "source": [
        "La siguiente función plot grafica múltiples curvas:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YkqTCx0RZh8"
      },
      "outputs": [],
      "source": [
        "def plot(X, Y=None, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
        "         ylim=None, xscale='linear', yscale='linear',\n",
        "         fmts=('-', 'm--', 'g-.', 'r:'), figsize=(3.5, 2.5), axes=None):\n",
        "    \"\"\"Grafica puntos de datos.\"\"\"\n",
        "    if legend is None:\n",
        "        legend = []\n",
        "\n",
        "    set_figsize(figsize)\n",
        "    axes = axes if axes else d2l.plt.gca()\n",
        "\n",
        "    # Regresa True si X (tensor o lista) tiene 1 eje\n",
        "    def has_one_axis(X):\n",
        "        return (hasattr(X, \"ndim\") and X.ndim == 1 or isinstance(X, list)\n",
        "                and not hasattr(X[0], \"__len__\"))\n",
        "\n",
        "    if has_one_axis(X):\n",
        "        X = [X]\n",
        "    if Y is None:\n",
        "        X, Y = [[]] * len(X), X\n",
        "    elif has_one_axis(Y):\n",
        "        Y = [Y]\n",
        "    if len(X) != len(Y):\n",
        "        X = X * len(Y)\n",
        "    axes.cla()\n",
        "    for x, y, fmt in zip(X, Y, fmts):\n",
        "        if len(x):\n",
        "            axes.plot(x, y, fmt)\n",
        "        else:\n",
        "            axes.plot(y, fmt)\n",
        "    set_axes(axes, xlabel, ylabel, xlim, ylim, xscale, yscale, legend)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hm9YuJLzRw3x"
      },
      "source": [
        "Podemos graficar la función $y = 2x-3$ en el punto $x = 1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "VvN_d5R1R-K0",
        "outputId": "29b4bfa1-3dd4-4b75-f7a2-a0bb26b9dc3b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-ce174248d596>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f(x)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlegend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f(x)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Tangent line (x=1)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-2a5b3f688eef>\u001b[0m in \u001b[0;36mplot\u001b[0;34m(X, Y, xlabel, ylabel, legend, xlim, ylim, xscale, yscale, fmts, figsize, axes)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mlegend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mset_figsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-47-8919525dde31>\u001b[0m in \u001b[0;36mset_figsize\u001b[0;34m(figsize)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"\"\"Set the figure size for matplotlib.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0muse_svg_display\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0md2l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'figure.figsize'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'd2l' is not defined"
          ]
        }
      ],
      "source": [
        "x = np.arange(0, 3, 0.1)\n",
        "plot(x, [f(x), 2 * x - 3], 'x', 'f(x)', legend=['f(x)', 'Tangent line (x=1)'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME9ueMHpSPtk"
      },
      "source": [
        "## Derivadas parciales\n",
        " En el aprendizaje profundo, las funciones suelen depender de muchas variables, es por eso que son de importancia las derivadas parciales, en donde se derivan funciones multivariables respecto a variables específicas.\n",
        "\n",
        " Sea $y = f(x_1,x_2,...,x_n)$ una función con $n$ variables. La derivada parcial de $y$ respecto a el i-ésimo parámetro $x_i$ es:\n",
        "\n",
        " $\\frac{\\partial y}{\\partial x_i} = \\lim_{h \\to 0} \\frac{f(x_1,...,x_{i-1},x_i+h,x_{i+1},...,x_n)-f(x_1,...,x_i,...,x_n)}{h}$\n",
        "\n",
        " Para calcular $\\frac{\\partial y}{\\partial x_i}$ simplemente podemos tratar a $x_1,...,x_{i-1},x_{i+1},...,x_n$ como constantes, y calcular la derivada de $y$ con respecto a $x_i$.\n",
        "\n",
        " ## Gradientes\n",
        " Podemos concatenar las derivadas parciales de una función multivariable con respecto a todas sus variables para obtener el vector gradiente de la función.\n",
        "\n",
        " Supongamos que la entrada de la función $f : \\mathbb R^n \\to \\mathbb R$ es un vector $n-$dimensional $\\textbf{x} = [x_1,x_2,...,x_n]$ y la salida es un escalar. El gradiente de la función $f(\\textbf{x})$ con respecto a $\\textbf{x}$ es un vector de $n$ derivadas parciales:\n",
        "\n",
        " $\\nabla_xf(\\textbf{x}) = [\\frac{\\partial f(\\textbf{x})}{\\partial x_1},\\frac{\\partial f(\\textbf{x})}{\\partial x_2},...,\\frac{\\partial f(\\textbf{x})}{\\partial x_n}]^T$\n",
        "\n",
        "\n",
        "**Reglas utilizadas al diferenciar funciones multivariadas**\n",
        "\n",
        "* $\\forall \\textbf{A} \\in \\mathbb R^{m \\times n}, \\nabla_x \\textbf{Ax} = \\textbf{A}^T$\n",
        "*  $\\forall \\textbf{A} \\in \\mathbb R^{n \\times m}, \\nabla_x \\textbf{x}^T\\textbf{A} = \\textbf{A}$\n",
        "*  $\\forall \\textbf{A} \\in \\mathbb R^{n \\times n}, \\nabla_x \\textbf{x}^T\\textbf{A}\\textbf{x} = (\\textbf{A}+\\textbf{A}^T)\\textbf{x}$\n",
        "* $\\nabla_x∥\\textbf{x}∥^2 = \\nabla_x \\textbf{x}^T\\textbf{x} = 2\\textbf{x}$\n",
        "\n",
        "\n",
        "## Regla de la cadena\n",
        "La regla de la cadena permite diferencias funciones compuestas.\n",
        "\n",
        "Consideremos funciones de una variable. Supongamos que las funciones $y = f(u)$ y $u = g(x)$ son ambas diferenciables, entonces la regla de la cadena establece que\n",
        "\n",
        "$\\frac{dy}{dx} = \\frac{dy}{du}\\frac{du}{dx}$\n",
        "\n",
        "Funciones multivariables. Supongamos que la funcipon diferenciable $y$ tiene variables $u_1,u_2,...,u_m$, donde cada función diferenciable $u_i$ tiene variables $x_1,x_2,...,x_n$. Por tanto, $y$ es una función de $x_1,x_2,...,x_n$. La regla de la cadena resulta:\n",
        "\n",
        "$\\frac{dy}{dx_i} = \\frac{dy}{du_1}\\frac{du_1}{dx_i}+\\frac{dy}{du_2}\\frac{du_2}{dx_i}+...+\\frac{dy}{du_m}\\frac{du_m}{dx_i}$\n",
        "\n",
        "para cualquier $i = 1,2,...,n$. \n",
        "\n",
        "\n",
        "## Diferenciación automática\n",
        "La diferenciación es crucial en casi todos los algoritmos de optimización del aprendizaje profundo.\n",
        "\n",
        "Basándonos en nuestro modelo diseñado, el sistema construye un gráfico computacional, rastreando qué datos se combinan a través de qué operaciones para producir la salida.\n",
        "La diferenciación automática permite al sistema retropropagar posteriormente los gradientes. Con retropropagar nos referimos a recorrer el gráfico computacional, rellenando las derivadas pariales con respecto a cada parámetro.\n",
        "\n",
        "#### Un ejemplo sencillo\n",
        "\n",
        "Supongamos que queremos diferenciar la función $ y = 2\\textbf{x}^T\\textbf{x}$ con respecto al vector columna $\\textbf{x}$. Para esto, se crea la variable $\\textbf{x}$ y se le asigna un valor inicial:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlsQq9lHzwor",
        "outputId": "b52af9d2-e8b8-4212-a68c-68c1f13ec442"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 1., 2., 3.])"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "x = torch.arange(4.0)\n",
        "x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wq3ifRhm_bI5"
      },
      "source": [
        "Antes de calcular el gradiente, se necesita un lugar para almacenarlo. Se debe tomar en cuenta que no se debe asignar nueva memoria cada vez que se tome una derivada respecto a un parámetro, ya que, probablemente se actualice millones de veces. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mnDpfb5Y_0On"
      },
      "outputs": [],
      "source": [
        "x.requires_grad_(True) # esto es lo mismo a poner x = torch.arange(4.0,requires_grad = True)\n",
        "x.grad # el valor por defecto es None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5Gf_VDB__I7",
        "outputId": "924bf2a1-159a-4c1c-8ce4-1063629e6c08"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(28., grad_fn=<MulBackward0>)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = 2*torch.dot(x,x) # funcion y \n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUv6UtRXAWE7"
      },
      "source": [
        "El vector x tiene longitud 4, y al hacer producto punto con él mismo, se obtiene un escalar que se asigna a y. El gradiente de $y$ respecto a cada componente de $\\textbf{x}$ se puede obtener llamando a la función de retropropagación, y luego imprimimos el gradiente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8nQRmO1Ar2e",
        "outputId": "8629e59e-39eb-4722-a42d-4989b329dab2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0.,  4.,  8., 12.])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.backward()\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dpR6Ak9A1M4"
      },
      "source": [
        "El gradiente de $y = 2\\textbf{x}^T\\textbf{x}$ con respecto a $\\textbf{x}$ debería ser $4\\textbf{x}$. Para verificar comparamos el gradiente obtenido con el valor que debe ser y comprobamos si la operación fue correcta:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG-2o7xKBGPT",
        "outputId": "3d5f4ed5-e7be-4517-d991-727b207b85e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad == 4*x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLC4HmvfBWC5"
      },
      "source": [
        "Calculando otra función de $x$, tenemos lo siguiente.\n",
        "El gradiente se acumula, entonces se debe limpiar previamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_AjB_RDBfeT",
        "outputId": "e3e1926b-7cb2-437b-ee81-74ad4791bdd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_() # limpiar gradiente\n",
        "y = x.sum() # funcion que es la suma de los elementos del vector x\n",
        "y.backward() # retropropagación\n",
        "x.grad # imprime gradiente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2VrNshFB_pj"
      },
      "source": [
        "## Retropropagación de variables no escalares\n",
        "La interpretación de la diferenciación de un vector $\\textbf{y}$ (que no es ecalar) con respecto a un vector $\\textbf{x}$ es una matriz. Para vectores de mayor orden y dimensión, el resultado podría ser un tensor de alto orden.\n",
        "\n",
        "En estos ejemplos no se pretende calcular la matriz de diferenciación, sino la suma de las derivadas parciales calculadas indivialmente para cada ejemplo en el lote.\n",
        "\n",
        "Llamar a la función _backward_ en una función no escalar requiere pasar un argumento \"gradient\" que especifica el gradiente de la función diferenciada con respecto a \"self\". En este ejemplo, simplemente queremos sumar las derivadas parciales, por lo que pasar un gradiente de puros unos es adecuado:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9sf6p23kEGO6",
        "outputId": "cb2d17c0-e649-4a2e-998d-f8023ca40a6e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 2., 4., 6.])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_()\n",
        "y = x*x\n",
        "\n",
        "y.sum().backward() # esto es igual a y.backward(torch.ones(len(x)))\n",
        "x.grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usHilpD0E54L"
      },
      "source": [
        "## Cálculo de desprendimiento\n",
        "\n",
        "Digamos que tenemos a una función $\\textbf{y}$ como una función de $\\textbf{x}$, y una función $\\textbf{z}$ como función de $\\textbf{y}$ y de $\\textbf{x}$. Si quisiéramos calcular el gradiente de $\\textbf{z}$ con respecto a $\\textbf{x}$, y tratar a $\\textbf{y}$ como una constante.\n",
        "\n",
        "Entonces podemos separar $\\textbf{y}$ para devolver una nueva variable $\\textbf{u}$ que tiene el mismo valor de $\\textbf{y}$ pero que descarta cualquier información sobre cómo se calculó y en el gráfico computacional, es decir, el gradiente no fluirá hacia atrás a través de $\\textbf{u}$ hasta $\\textbf{x}$. De este modo, la siguiente función de retropropagación calcula la derivada parcial de $\\textbf{z} = \\textbf{u}*\\textbf{x}$ con respecto a $\\textbf{x}$, tratando a $\\textbf{u}$ como una constante, en lugar de hacer la derivada parcial de $\\textbf{z} = \\textbf{x}*\\textbf{x}*\\textbf{x}$ con respecto a $\\textbf{x}$.\n",
        "\n",
        "Esto se muestra a continuación:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hvk-LQRHIxOB",
        "outputId": "fd4adbdf-5e79-47fd-86fb-3fbd46ca3210"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([True, True, True, True])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.grad.zero_()\n",
        "y = x * x\n",
        "u = y.detach()\n",
        "z = u * x\n",
        "\n",
        "z.sum().backward()\n",
        "x.grad == u"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-sMbthsJEJh"
      },
      "source": [
        "## Cálculo del gradiente del flujo de control en Python\n",
        "En el siguiente código, el número de iteraciones del bucle while y la evaluación de la sentencia if depende del valor de la entrada a.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TW9fxIKLVfO"
      },
      "outputs": [],
      "source": [
        "def f(a):\n",
        "    b = a * 2\n",
        "    while b.norm() < 1000:\n",
        "        b = b * 2\n",
        "    if b.sum() > 0:\n",
        "        c = b\n",
        "    else:\n",
        "        c = 100 * b\n",
        "    return c\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLCZYgeSLXr_"
      },
      "source": [
        "Calculando el gradiente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1oOYk2yyLZfW"
      },
      "outputs": [],
      "source": [
        "a = torch.randn(size=(), requires_grad=True)\n",
        "d = f(a)\n",
        "d.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7abwOELLe-9"
      },
      "source": [
        "En la función $f$ definida previamente es lineal a trozos en su entrada $a$, es decir, para cualquier $a$ existe algún escalar constante $k$ tal que, $f(a) = k*a$, donde el valor de $k$ depende de la entrada $a$. En consecuencia $d/a$ nos permite verificar que el gradiente es correcto.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHzXnGdDL2Qr",
        "outputId": "ef6f67d0-0e14-49c1-92db-8628e2707721"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a.grad == d / a"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULsivjPOMC3Q"
      },
      "source": [
        "# Probabilidad\n",
        "## Teoría básica de la probabilidad\n",
        "\n",
        "Si lanzamos un dado y queremos saber cuál es la probabilidad de ver un 1 en lugar de otro dígito. Si el dado es justo, los seis resultados $\\{1,...,6\\}$ tienen la misma probabilidad de ocurrir. Decimos entonces que el 1 puede salir con una probabilidad de $\\frac{1}{6}$.\n",
        "\n",
        "Un enfoque natural para cada valor es tomar el recuento individual para un valor y dividirlo por el número total de lanzamientos, dándonos una estimación de la probabilidad de un evento determinado.\n",
        "\n",
        "Importamos lo siguiente:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "iKP2Fs-KFhAN",
        "outputId": "077caeed-8901-4fe7-eaad-42ec3a38c3ce"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-16ab6a2459a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmultinomial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0md2l\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'd2l'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from torch.distributions import multinomial\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dXhgsYJGSWv"
      },
      "source": [
        "En estadística se llama muestreo al proceso de extraer ejemplos de las distribuciones de probabilidad. La distribución que asigna probabilidades a un número de opciones discretas se llama distribución multinomial.\n",
        "\n",
        "Para extraer una muestra, se pasa un vector de probabilidades. La salida es un vector de la misma longitud: su valor en el índice $i$ es el número de veces que el resultado de la muestra corresponde a $i$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeGv7xRsG_xs",
        "outputId": "953940ca-4550-4be1-9941-93e03cff6f9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 1., 0.])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "fair_probs = torch.ones([6]) / 6\n",
        "multinomial.Multinomial(1, fair_probs).sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq9Co5xAHHqV"
      },
      "source": [
        "Si se ejecuta el código anterior varias veces, se obtendrán valores aleatorios. La función utilizada soporta la extracción de múltiples muestras a la vez, devoldiendo un array de muestras independientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOELu9tHHiUm",
        "outputId": "9d44c8bd-fe56-4128-fa1e-8c8fd5ce4f2b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2., 1., 1., 2., 4., 0.])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "multinomial.Multinomial(10, fair_probs).sample()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YumlWPVhHlmU"
      },
      "source": [
        "El código anterior ya no solo simula la tirada de un dado una vez, sino que la simula para 10 tiradas, y podemos ver cuantas veces salió cada número. En concreto, calculamos la frecuencia relativa como estimación de la probabilidad real.\n",
        "\n",
        "Para 1000 tiradas:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9TGgxYMWIGe2",
        "outputId": "cdab0d57-25ab-49ca-d98c-395b43fc4eff"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.1670, 0.1820, 0.1710, 0.1600, 0.1640, 0.1560])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "counts = multinomial.Multinomial(1000, fair_probs).sample()\n",
        "counts / 1000  # frecuencia relativa como estimación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64lbEz8GIRkH"
      },
      "source": [
        "Las probabilidades obtenidas parecen bastante buenas, debido a que la probabilidad real antes mencionada es de $\\frac{1}{6} ≈ 0.167$.\n",
        "\n",
        "Podemos visualizar cómo estas probabilidades convergen con el tiempo hacia la probabilidad real.\n",
        "\n",
        "Realizando 500 grupos de experimentos en los que cada grupo extrae 10 muestras:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fiP_OcxXI7DL"
      },
      "outputs": [],
      "source": [
        "counts = multinomial.Multinomial(10, fair_probs).sample((500,))\n",
        "cum_counts = counts.cumsum(dim=0)\n",
        "estimates = cum_counts / cum_counts.sum(dim=1, keepdims=True)\n",
        "\n",
        "d2l.set_figsize((6, 4.5))\n",
        "for i in range(6):\n",
        "    d2l.plt.plot(estimates[:, i].numpy(),\n",
        "                 label=(\"P(die=\" + str(i + 1) + \")\"))\n",
        "d2l.plt.axhline(y=0.167, color='black', linestyle='dashed')\n",
        "d2l.plt.gca().set_xlabel('Groups of experiments')\n",
        "d2l.plt.gca().set_ylabel('Estimated probability')\n",
        "d2l.plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHEOAeieI9P3"
      },
      "source": [
        "Cada curva corresponde a uno de los seis valores del dado. La línea negra discontinua da la verdadera probabilidad subyacente. A medida que se obtienen más datos realizando más experimentos, las 6 curvas convergen hacia la verdadera probabilidad.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXXiy5PtJOxX"
      },
      "source": [
        "# Documentación\n",
        "## Cómo encontrar todas las funciones y clases de un módulo\n",
        "\n",
        "Para saber qué funciones y clases se pueden llamar en un módulo, se utiliza la función dir.\n",
        "Por ejemplo, con el módulo para generar números aleatorios:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaac4zeiJuwB",
        "outputId": "4eac1155-2871-4db7-8b33-681e085759d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['AbsTransform', 'AffineTransform', 'Bernoulli', 'Beta', 'Binomial', 'CatTransform', 'Categorical', 'Cauchy', 'Chi2', 'ComposeTransform', 'ContinuousBernoulli', 'CorrCholeskyTransform', 'Dirichlet', 'Distribution', 'ExpTransform', 'Exponential', 'ExponentialFamily', 'FisherSnedecor', 'Gamma', 'Geometric', 'Gumbel', 'HalfCauchy', 'HalfNormal', 'Independent', 'IndependentTransform', 'Kumaraswamy', 'LKJCholesky', 'Laplace', 'LogNormal', 'LogisticNormal', 'LowRankMultivariateNormal', 'LowerCholeskyTransform', 'MixtureSameFamily', 'Multinomial', 'MultivariateNormal', 'NegativeBinomial', 'Normal', 'OneHotCategorical', 'OneHotCategoricalStraightThrough', 'Pareto', 'Poisson', 'PowerTransform', 'RelaxedBernoulli', 'RelaxedOneHotCategorical', 'ReshapeTransform', 'SigmoidTransform', 'SoftmaxTransform', 'StackTransform', 'StickBreakingTransform', 'StudentT', 'TanhTransform', 'Transform', 'TransformedDistribution', 'Uniform', 'VonMises', 'Weibull', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'bernoulli', 'beta', 'biject_to', 'binomial', 'categorical', 'cauchy', 'chi2', 'constraint_registry', 'constraints', 'continuous_bernoulli', 'dirichlet', 'distribution', 'exp_family', 'exponential', 'fishersnedecor', 'gamma', 'geometric', 'gumbel', 'half_cauchy', 'half_normal', 'identity_transform', 'independent', 'kl', 'kl_divergence', 'kumaraswamy', 'laplace', 'lkj_cholesky', 'log_normal', 'logistic_normal', 'lowrank_multivariate_normal', 'mixture_same_family', 'multinomial', 'multivariate_normal', 'negative_binomial', 'normal', 'one_hot_categorical', 'pareto', 'poisson', 'register_kl', 'relaxed_bernoulli', 'relaxed_categorical', 'studentT', 'transform_to', 'transformed_distribution', 'transforms', 'uniform', 'utils', 'von_mises', 'weibull']\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(dir(torch.distributions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-FrJBn_Jy3K"
      },
      "source": [
        "De forma general, se pueden ignorar las funciones que empiezan y terminan con _ (son objetos especiales en Python) o las funciones que empizan solo con _ (son normalmente funciones internas).\n",
        "\n",
        "#### Encontrar el uso de funciones y clases específicas\n",
        "\n",
        "Para obtener instrucciones más específicas sobre cómo utilizar una determinada función o clase, podemos invocar a la función de ayuda.\n",
        "\n",
        "Ejemplo: función ones de los tensores.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-xPtFOMKXLP",
        "outputId": "2ce92c65-17d1-465e-e2c4-c69032492c57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on built-in function ones:\n",
            "\n",
            "ones(...)\n",
            "    ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n",
            "    \n",
            "    Returns a tensor filled with the scalar value `1`, with the shape defined\n",
            "    by the variable argument :attr:`size`.\n",
            "    \n",
            "    Args:\n",
            "        size (int...): a sequence of integers defining the shape of the output tensor.\n",
            "            Can be a variable number of arguments or a collection like a list or tuple.\n",
            "    \n",
            "    Keyword arguments:\n",
            "        out (Tensor, optional): the output tensor.\n",
            "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
            "            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n",
            "        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n",
            "            Default: ``torch.strided``.\n",
            "        device (:class:`torch.device`, optional): the desired device of returned tensor.\n",
            "            Default: if ``None``, uses the current device for the default tensor type\n",
            "            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n",
            "            for CPU tensor types and the current CUDA device for CUDA tensor types.\n",
            "        requires_grad (bool, optional): If autograd should record operations on the\n",
            "            returned tensor. Default: ``False``.\n",
            "    \n",
            "    Example::\n",
            "    \n",
            "        >>> torch.ones(2, 3)\n",
            "        tensor([[ 1.,  1.,  1.],\n",
            "                [ 1.,  1.,  1.]])\n",
            "    \n",
            "        >>> torch.ones(5)\n",
            "        tensor([ 1.,  1.,  1.,  1.,  1.])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(torch.ones)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vos8KaAwKa76"
      },
      "source": [
        "A partir de su documentación, podemos ver que la función ones crea un nuevo tensor con la forma especificada y establece todos los elementos con el valor de 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCxC28H8Kldb",
        "outputId": "01c5b27b-e759-4beb-a158-fbce3140c4df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1., 1., 1., 1.])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.ones(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG-MhLWhKoXb"
      },
      "source": [
        "En Jupyter Notebook, podemos utilizar el signo \"?\" para mostrar el documento en otra ventana. Por ejemplo, list? creará un contenido casi idéntico a help(list), mostrándolo en una nueva ventana del navegador. Además, si se utilizan dos signos \"??\", también se mostrará el código Python que implementa la función."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referencia\n",
        "Dive into Deep Learning. Recuperado de: http://www.d2l.ai/index.html"
      ],
      "metadata": {
        "id": "3nzLqUQ4CKfp"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "PyTorch_preliminares.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN6+O/jH+EknfCq+kKPJ8wb",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}